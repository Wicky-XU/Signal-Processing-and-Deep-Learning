#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Auto Transcript Project - ä¸»ç¨‹åº
è‡ªåŠ¨è§†é¢‘è½¬å½•ç³»ç»Ÿä¸»å…¥å£

åŠŸèƒ½:
1. äººè„¸è¯†åˆ« - è¯†åˆ«è§†é¢‘ä¸­çš„è¯´è¯è€…
2. è¯­éŸ³è¯†åˆ« - å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬
3. è‡ªåŠ¨ç¿»è¯‘ - å°†æ³•è¯­ç¿»è¯‘ä¸ºè‹±è¯­
4. æ—¶é—´æˆ³æ ‡è®° - ä¸ºæ¯å¥è¯æ·»åŠ æ—¶é—´æˆ³
"""

import os
import sys
import glob
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from src.face_recognition import FaceRecognizer
    from src.speech_recognition import SpeechRecognizer
    from src.translation import Translator
    from src.utils import (
        check_dependencies,
        validate_input_file,
        save_transcript_results,
        print_project_banner,
        cleanup_temp_files,
        check_models_cache,
        setup_models_cache,
        print_models_info
    )
    
    MODULES_OK = True
except ImportError as e:
    print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿srcç›®å½•ä¸‹çš„æ‰€æœ‰æ¨¡å—æ–‡ä»¶å­˜åœ¨")
    print("å¦‚æœæ˜¯äººè„¸è¯†åˆ«æ¨¡å—å¤±è´¥ï¼Œè¯·å®‰è£…: pip install facenet-pytorch torch torchvision")
    MODULES_OK = False


def auto_transcript(input_file, output_file):
    """
    ä¸»è½¬å½•å‡½æ•°
    
    Args:
        input_file: è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºè½¬å½•æ–‡ä»¶è·¯å¾„
        
    Returns:
        bool: è½¬å½•æ˜¯å¦æˆåŠŸ
    """
    
    if not MODULES_OK:
        print("æ¨¡å—æœªæ­£ç¡®åŠ è½½ï¼Œæ— æ³•æ‰§è¡Œè½¬å½•")
        return False
    
    print(f"å¼€å§‹å¤„ç†è§†é¢‘: {input_file}")
    
    try:
        # Step 1: äººè„¸è¯†åˆ«
        print("\nStep 1: äººè„¸è¯†åˆ«")
        print("-" * 30)
        
        try:
            face_recognizer = FaceRecognizer()
            speaker_name = face_recognizer.identify_speaker(input_file)
            print(f"äººè„¸è¯†åˆ«å®Œæˆï¼Œè¯´è¯è€…: {speaker_name}")
        except Exception as e:
            print(f"äººè„¸è¯†åˆ«å‡ºç°é”™è¯¯: {e}")
            print("ä½¿ç”¨é»˜è®¤è¯´è¯è€…åç§°")
            speaker_name = "Speaker"
        
        # Step 2: è¯­éŸ³è¯†åˆ«
        print(f"\nStep 2: è¯­éŸ³è¯†åˆ«")
        print("-" * 30)
        speech_recognizer = SpeechRecognizer()
        transcript_data = speech_recognizer.transcribe_video(input_file)
        
        if not transcript_data:
            print("æœªèƒ½è¯†åˆ«å‡ºä»»ä½•è¯­éŸ³å†…å®¹")
            return False
        
        # Step 3: ç¿»è¯‘å¤„ç†
        print(f"\nStep 3: ç¿»è¯‘å¤„ç†")
        print("-" * 30)
        translator = Translator()
        final_results = translator.process_transcript(transcript_data, speaker_name)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nè½¬å½•ç»“æœ:")
        print("=" * 60)
        for line in final_results:
            print(line)
        print("=" * 60)
        
        # ä¿å­˜ç»“æœ
        success = save_transcript_results(final_results, output_file, input_file)
        
        if success:
            print(f"è½¬å½•å®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
            return True
        else:
            print("ä¿å­˜ç»“æœæ—¶å‡ºç°é”™è¯¯")
            return False
        
    except Exception as e:
        print(f"è½¬å½•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’ŒGPUç¼“å­˜
        cleanup_temp_files()
        
        # æ¸…ç†GPUç¼“å­˜ï¼ˆå¦‚æœä½¿ç”¨äº†GPUï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except ImportError:
            pass


def find_input_video():
    """
    æŸ¥æ‰¾è¾“å…¥è§†é¢‘æ–‡ä»¶
    
    Returns:
        str: è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å›None
    """
    input_dir = Path("data/input")
    
    if not input_dir.exists():
        print(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        print("è¯·åˆ›å»ºdata/inputç›®å½•å¹¶æ”¾ç½®è§†é¢‘æ–‡ä»¶")
        return None
    
    # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.flv']
    video_files = []
    
    for ext in video_extensions:
        video_files.extend(glob.glob(str(input_dir / ext)))
    
    if not video_files:
        print(f"åœ¨{input_dir}ç›®å½•ä¸‹æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        print(f"æ”¯æŒçš„æ ¼å¼: {', '.join(video_extensions)}")
        return None
    
    # è¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„è§†é¢‘æ–‡ä»¶
    return video_files[0]


def check_face_recognition_dependencies():
    """æ£€æŸ¥äººè„¸è¯†åˆ«ä¸“ç”¨ä¾èµ–"""
    try:
        import torch
        import torchvision
        from facenet_pytorch import MTCNN, InceptionResnetV1
        
        print("æ·±åº¦å­¦ä¹ ä¾èµ–æ£€æŸ¥é€šè¿‡")
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if torch.cuda.is_available():
            print(f"GPUå¯ç”¨: {torch.cuda.get_device_name(0)}")
        else:
            print("GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
        
        return True
        
    except ImportError as e:
        print(f"äººè„¸è¯†åˆ«ä¾èµ–ç¼ºå¤±: {e}")
        print("è¯·å®‰è£…: pip install torch torchvision facenet-pytorch")
        return False
    """
    ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
def generate_output_filename():
    """
    ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_dir = Path("data/output")
    return str(output_dir / f"transcript_{timestamp}.txt")


def main():
    """ä¸»å‡½æ•°"""
    
    # æ‰“å°é¡¹ç›®ä¿¡æ¯
    print_project_banner()
    
    # æ£€æŸ¥åŸºç¡€ä¾èµ–
    if not check_dependencies():
        print("\nè¯·å®‰è£…ç¼ºå¤±çš„åŸºç¡€ä¾èµ–åŒ…åé‡æ–°è¿è¡Œç¨‹åº")
        return
    
    # æ£€æŸ¥äººè„¸è¯†åˆ«ä¸“ç”¨ä¾èµ–
    if not check_face_recognition_dependencies():
        print("\näººè„¸è¯†åˆ«åŠŸèƒ½å°†å—é™ï¼Œå»ºè®®å®‰è£…æ·±åº¦å­¦ä¹ ä¾èµ–åŒ…")
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        try:
            user_input = input("æ˜¯å¦ç»§ç»­è¿è¡Œï¼ˆå¯èƒ½å½±å“äººè„¸è¯†åˆ«å‡†ç¡®æ€§ï¼‰ï¼Ÿ(y/n): ")
            if user_input.lower() not in ['y', 'yes', 'æ˜¯']:
                print("ç¨‹åºé€€å‡º")
                return
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
            return
    else:
        # æ£€æŸ¥å’Œè®¾ç½®æ¨¡å‹ç¼“å­˜
        print("\nğŸ“¦ æ£€æŸ¥æ¨¡å‹ç¼“å­˜...")
        cache_info = check_models_cache()
        
        if not cache_info['exists']:
            print("é¦–æ¬¡è¿è¡Œï¼Œè®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•...")
            setup_models_cache()
        
        print_models_info()
    
    # æ£€æŸ¥æ¨¡å—
    if not MODULES_OK:
        print("\né¡¹ç›®æ¨¡å—åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥srcç›®å½•")
        return
    
    # æŸ¥æ‰¾è¾“å…¥æ–‡ä»¶
    print("\næŸ¥æ‰¾è¾“å…¥è§†é¢‘...")
    input_file = find_input_video()
    if not input_file:
        return
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not validate_input_file(input_file):
        return
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    output_file = generate_output_filename()
    
    print(f"\né…ç½®ä¿¡æ¯:")
    print(f"  è¾“å…¥æ–‡ä»¶: {Path(input_file).name}")
    print(f"  è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # æ‰§è¡Œè½¬å½•
    print(f"\nå¼€å§‹è‡ªåŠ¨è½¬å½•...")
    success = auto_transcript(input_file, output_file)
    
    if success:
        print(f"\nğŸ‰ è½¬å½•æˆåŠŸå®Œæˆ!")
    else:
        print(f"\nâŒ è½¬å½•å¤±è´¥")


if __name__ == "__main__":
    main()